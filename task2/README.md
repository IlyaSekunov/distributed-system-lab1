*   **Замеры 1: Разбиение по строкам.** Характерный признак — хорошая производительность на "вытянутых" матрицах (когда `n` (строк) мало, а `m` (столбцов) много). Это логично, так как каждому процессу достается несколько полных строк и он может независимо вычислить свой элемент результирующего вектора.
*   **Замеры 2: Разбиение по столбцам.** Характерный признак — хорошая производительность на "сплюснутых" матрицах (когда `m` мало, а `n` много). В этой схеме каждому процессу достается часть столбцов, и для вычисления требуется операция редукции, что хорошо работает только при определенных условиях.
*   **Замеры 3: Блочное разбиение.** Характерный признак — работа только с квадратными матрицами (`n = m`). Это единственные замеры для `p=4`, что также указывает на блочную декомпозицию, которая эффективна при квадратной форме данных и квадратном количестве процессов.

---

### Сравнительный анализ алгоритмов

#### 1. Разбиение по строкам (Замеры 1, p=6)

**Принцип:** Матрица делится на группы строк между процессами. Каждый процесс умножает свои строки на весь вектор и получает часть результирующего вектора.

**Преимущества:**
*   **Минимальные коммуникации:** Процессы обмениваются только исходным вектором в начале (операция `MPI_Bcast`). После этого вычисления полностью независимы.
*   **Высокая эффективность для "вытянутых" матриц:** Идеально подходит для случаев, когда число строк `n` сравнимо или меньше числа процессов `p`, а число столбцов `m` велико. Например:
    *   `(n=10, m=1000000)`: `t(1)=76.839`, `t(p)=73.136` (почти нет потерь).
    *   `(n=100, m=1000000)`: `t(1)=774.785`, `t(p)=633.819` **(ускорение ~1.22)**.

**Недостатки:**
*   **Неэффективность для "сплюснутых" матриц:** Когда строк много, а столбцов мало, объем вычислений на процесс мал, а накладные расходы на коммуникации становятся значительными. Например:
    *   `(n=1000000, m=10)`: `t(1)=73.638`, `t(p)=86.842` **(замедление!)**.
*   **Дисбаланс нагрузки:** Если `n` не кратно `p`, некоторые процессы получат больше работы, чем другие.

**Выводы:** Алгоритм прост в реализации, обладает отличной масштабируемостью по столбцам, но плохо подходит для матриц с малым числом столбцов.

#### 2. Разбиение по столбцам (Замеры 2, p=6)

**Принцип:** Матрица делится на группы столбцов, и копия вектора также делится. Каждый процесс вычисляет частичную сумму. В конце все частичные суммы складываются с помощью `MPI_Reduce`.

**Преимущества:**
*   **Эффективен для "сплюснутых" матриц:** Хорошо работает, когда число столбцов `m` невелико. Например:
    *   `(n=10000, m=10)`: `t(1)=0.752`, `t(p)=0.743` (минимальные потери).
*   **Равномерное распределение данных:** Если `m` велико, работа распределяется хорошо.

**Недостатки:**
*   **Высокие коммуникационные затраты:** Требуется операция глобальной редукции `MPI_Reduce`, которая более затратна, чем широковещательная рассылка.
*   **Неэффективность для "вытянутых" матриц:** Когда столбцов много, а строк мало, каждый процесс выполняет много работы, но объем результирующих данных для редукции большой. Например:
    *   `(n=10, m=1000000)`: `t(1)=76.111`, `t(p)=80.591` **(замедление!)**.
*   **Явное ухудшение при росте `n`:** С увеличением размера задачи и числа процессов время редукции сильно растет, что видно на примере `(n=10000000, m=10)`: `t(p) > t(1)`.

**Выводы:** Алгоритм может быть полезен в специфических случаях с малым числом столбцов, но в целом проигрывает разбиению по строкам из-за дорогостоящей операции редукции.

#### 3. Блочное разбиение (Замеры 3, p=4)

**Принцип:** Матрица разбивается на прямоугольные блоки (в данном случае, скорее всего, на квадратные, так как `n=m`), которые распределяются между процессами. Каждый процесс участвует в вычислении своей части результата, требуются более сложные коммуникации.


**Преимущества:**
*   **Наилучшая масштабируемость для больших квадратных матриц:** Оптимально использует двумерную сетку процессов, минимизируя как объем пересылаемых данных, так и максимальную загрузку отдельного процесса.
*   **Балансировка нагрузки:** Позволяет более гибко распределить работу, особенно когда число процессов не является степенью двойки.
*   **Высокое ускорение на больших задачах:** Для большой квадратной матрицы `(n=10000, m=10000)` видно значительное ускорение: `t(1)=1711.112`, `t(p)=1363.839` **(ускорение ~1.25)**. Это лучше, чем у конкурентов для аналогичных пропорций.

**Недостатки:**
*   **Высокая сложность реализации:** Требует организации двумерной топологии процессов (`MPI_Cart_create`), сложных операций сбора и разбора данных.
*   **Большие накладные расходы на маленьких задачах:** На малых матрицах коммуникации полностью "убивают" выгоду от параллелизма:
    *   `(n=100, m=100)`: `t(1)=0.126`, `t(p)=0.398` **(замедление в 3 раза!)**.
*   **Эффективен только для больших данных:** Как видно из замеров, преимущества начинают проявляться только при размерах матрицы порядка тысяч (`n=1024` и больше).

**Выводы:** Это самый сложный, но и самый мощный алгоритм. Он не подходит для небольших или сильно вытянутых матриц, но является лучшим выбором для умножения больших квадратных (или близких к квадратным) матриц на вектор, особенно на большом количестве процессов.

---

### Сводная таблица сравнения

| Критерий | Разбиение по строкам | Разбиение по столбцам | Блочное разбиение |
| :--- | :--- | :--- | :--- |
| **Простота реализации** | **Очень высокая** | Высокая | **Низкая** |
| **Коммуникации** | `MPI_Bcast` вектора | `MPI_Reduce` результата | Сложные (топологии, сборки) |
| **Лучший случай** | Мало строк, много столбцов | Много строк, мало столбцов | **Большие квадратные матрицы** |
| **Худший случай** | Много строк, мало столбцов | Мало строк, много столбцов | Маленькие или вытянутые матрицы |
| **Эффективность** | Высокая в своем лучшем случае | Умеренная в своем лучшем случае | **Самая высокая для больших n=m** |
| **Масштабируемость** | Хорошая по столбцам | Ограниченная (редукцией) | **Наилучшая (в перспективе)** |

### Общие выводы

1.  **"Универсального" алгоритма нет.** Выбор оптимального алгоритма **сильно зависит от формы матрицы (`n` и `m`)** и размера задачи.
2.  **Пороговый эффект.** Все параллельные алгоритмы начинают давать выгоду только после преодоления определенного порога размера задачи. На малых данных (`n, m < 1000`) накладные расходы на коммуникации почти всегда приводят к замедлению.
3.  **Разбиение по строкам — хороший выбор по умолчанию.** Если вы не знаете, с какими данными будете работать, или имеете дело с вытянутыми матрицами, этот алгоритм является наиболее надежным и простым. Он показал стабильно хорошие результаты в Замерах 1 для задач с большим `m`.
4.  **Разбиение по столбцам — узкоспециализированный инструмент.** Его стоит рассматривать только для задач, где `m` очень мало (например, `m=1` — умножение на один вектор), и при этом `n` велико.
5.  **Блочное разбиение — оружие для высокопроизводительных вычислений.** Его стоит применять для очень больших, плотных квадратных матриц, когда вы готовы пожертвовать простотой кода для достижения максимальной производительности и масштабируемости на большом количестве вычислительных узлов.
6.  **Эффективность (`e(p)`) во всех случаях далека от 1.** Это нормально для задач с интенсивными коммуникациями. С ростом размера задачи эффективность обычно увеличивается, приближаясь к идеалу, что и подтверждается замерами (например, в блочном разбиении для `n=10000` эффективность уже заметно выше, чем для `n=100`).
